{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\nicola.rudow\\AppData\\Local\\Temp\\ipykernel_12040\\3943300725.py:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  file_path = \"data\\SuchtGPT_Angebot_nexus_final.pdf\"\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data\\SuchtGPT_Angebot_nexus_final.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import os\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)\n",
    "print(inhalt_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#import pdfplumber\n",
    "#funktioniert für einseitige inhaltsverzeichnisse\n",
    "\n",
    "def extract_text_and_toc_end_page(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "            # Überprüfe, ob das Inhaltsverzeichnis gefunden wurde\n",
    "            if \"Inhalt\" in text:\n",
    "                # Extrahiere den Text nach \"Inhalt\"\n",
    "                toc_text = text.split(\"Inhalt\")[1]\n",
    "                \n",
    "                # Gehe weiter, um die letzte Seite des Inhaltsverzeichnisses zu finden\n",
    "                for j in range(i + 1, len(pdf.pages)):\n",
    "                    next_page_text = pdf.pages[j].extract_text()\n",
    "                    if \"1\" in next_page_text:  # Beispiel für ein Schlüsselwort, das das Ende anzeigt\n",
    "                        return toc_text, j  # j ist der Seitenindex des Kapitels\n",
    "                return toc_text, len(pdf.pages)  # Wenn kein Kapitel gefunden wird, gehe davon aus, dass das Inhaltsverzeichnis die letzte Seite erreicht hat\n",
    "\n",
    "    return None, None  # Wenn kein Inhaltsverzeichnis gefunden wird\n",
    "    \n",
    "toc_text, inhalt_end = extract_text_and_toc_end_page(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probierzeug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_toc_and_end_page(file_path):\n",
    "    toc_text = \"\"\n",
    "    toc_end_page = None\n",
    "\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "            # Überprüfe, ob das Inhaltsverzeichnis gefunden wurde\n",
    "            if \"Inhalt\" in text:\n",
    "                toc_text = text.split(\"Inhalt\")[1]  # Extrahiere den Text nach \"Inhalt\"\n",
    "                toc_end_page = i  # Setze die aktuelle Seite als die letzte Seite des Inhaltsverzeichnisses\n",
    "            elif toc_text:  # Wenn wir bereits im Inhaltsverzeichnis sind\n",
    "                # Überprüfe, ob der Text des Inhaltsverzeichnisses noch vorhanden ist\n",
    "                if toc_text not in text:\n",
    "                    break  # Beende die Schleife, wenn der Text nicht mehr vorhanden ist\n",
    "                toc_end_page = i  # Aktualisiere die letzte Seite des Inhaltsverzeichnisses\n",
    "\n",
    "    return toc_text, toc_end_page\n",
    "\n",
    "toc_text, toc_end_page_index = extract_toc_and_end_page(file_path)\n",
    "\n",
    "if toc_text:\n",
    "    print(f\"Inhaltsverzeichnis:\\n{toc_text}\")\n",
    "    print(f\"Das Inhaltsverzeichnis endet auf Seite: {toc_end_page_index}\")  # +1 für die 1-basierte Seitenzählung\n",
    "else:\n",
    "    print(\"Kein Inhaltsverzeichnis gefunden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_toc_and_end_page(file_path):\n",
    "    toc_text = \"\"\n",
    "    toc_end_page = None\n",
    "    in_toc = False\n",
    "\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "            if \"Inhalt\" in text and not in_toc:\n",
    "                toc_text = text.split(\"Inhalt\")[1]  # Extrahiere den Text nach \"Inhalt\"\n",
    "                in_toc = True  # Wir sind jetzt im Inhaltsverzeichnis\n",
    "                toc_end_page = i  # Setze die aktuelle Seite als die letzte Seite des Inhaltsverzeichnisses\n",
    "            elif in_toc:  # Wenn wir im Inhaltsverzeichnis sind\n",
    "                # Überprüfe, ob der Text weiterhin relevant ist\n",
    "                toc_text += \"\\n\" + text  # Füge den Text zur Inhaltsverzeichnis-Variable hinzu\n",
    "                toc_end_page = i  # Aktualisiere die letzte Seite des Inhaltsverzeichnisses\n",
    "                # Optional: Beende die Schleife, wenn eine bestimmte Bedingung erfüllt ist\n",
    "                if len(text.strip()) == 0:  # Wenn die Seite leer ist, breche ab\n",
    "                    break\n",
    "\n",
    "    return toc_text, toc_end_page\n",
    "\n",
    "toc_text, toc_end_page_index = extract_toc_and_end_page(file_path)\n",
    "\n",
    "if toc_text:\n",
    "    print(f\"Inhaltsverzeichnis:\\n{toc_text}\")\n",
    "    print(f\"Das Inhaltsverzeichnis endet auf Seite: {toc_end_page_index + 1}\")  # +1 für die 1-basierte Seitenzählung\n",
    "    print(f\"Länge des extrahierten Textes: {len(toc_text)} Zeichen\")  # Ausgabe der Länge des extrahierten Textes\n",
    "else:\n",
    "    print(\"Kein Inhaltsverzeichnis gefunden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "def extract_toc_and_end_page(file_path):\n",
    "    toc_text = \"\"\n",
    "    toc_end_page = None\n",
    "    in_toc = False\n",
    "    matches = []  # Liste für die gefundenen Abschnitte\n",
    "\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "            if \"Inhalt\" in text and not in_toc:\n",
    "                toc_text = text.split(\"Inhalt\")[1]  # Extrahiere den Text nach \"Inhalt\"\n",
    "                in_toc = True  # Wir sind jetzt im Inhaltsverzeichnis\n",
    "                toc_end_page = i  # Setze die aktuelle Seite als die letzte Seite des Inhaltsverzeichnisses\n",
    "                # Suche nach Abschnitten, die typischerweise im Inhaltsverzeichnis vorkommen\n",
    "                matches = re.findall(r'(\\d+\\.\\s.*?)(?=\\n\\d+\\.\\s|$)', toc_text, re.DOTALL)  # Beispiel für Kapitelnummern\n",
    "            elif in_toc:  # Wenn wir im Inhaltsverzeichnis sind\n",
    "                toc_text += \"\\n\" + text  # Füge den Text zur Inhaltsverzeichnis-Variable hinzu\n",
    "                toc_end_page = i  # Aktualisiere die letzte Seite des Inhaltsverzeichnisses\n",
    "\n",
    "                # Überprüfen, ob wir das Ende des Inhaltsverzeichnisses erreicht haben\n",
    "                if len(matches) > 0:\n",
    "                    for j, match in enumerate(matches):\n",
    "                        start = toc_text.find(match)  # Startposition des aktuellen Abschnitts\n",
    "                        # Definiere die Endposition als den Start des nächsten Abschnitts oder das Ende des Textes\n",
    "                        end = toc_text.find(matches[j + 1]) if j + 1 < len(matches) else len(toc_text)\n",
    "                        section_text = toc_text[start:end].strip()  # Extrahiere den Abschnitt\n",
    "                        # Optional: Hier kannst du die extrahierten Abschnitte speichern oder verarbeiten\n",
    "                else:\n",
    "                    break  # Beende die Schleife, wenn keine Abschnitte mehr gefunden werden\n",
    "\n",
    "    return toc_text, toc_end_page\n",
    "\n",
    "\n",
    "toc_text, toc_end_page_index = extract_toc_and_end_page(file_path)\n",
    "\n",
    "if toc_text:\n",
    "    print(f\"Inhaltsverzeichnis:\\n{toc_text}\")\n",
    "    print(f\"Das Inhaltsverzeichnis endet auf Seite: {toc_end_page_index + 1}\")  # +1 für die 1-basierte Seitenzählung\n",
    "else:\n",
    "    print(\"Kein Inhaltsverzeichnis gefunden.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ende probierzeug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(text) #entkommentieren, falls man den output testen will"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex für den ersten Abschnitt\n",
    "first_pattern = r\"^(?:(1(?:\\.\\d+)*\\.?|AP 1(?:\\.\\d+)*\\.?|AP 0\\.?)(?:[.:]?)\\s+([^\\.\\n]+))\"\n",
    "\n",
    "\n",
    "#Extrahieren der Abschnittsnamen im Inhaltsverzeichnis\n",
    "# Regex für den ersten Abschnitt\n",
    "first_pattern = r\"^(?:(1(?:\\.\\d+)*\\.?|AP 1(?:\\.\\d+)*\\.?|AP 0\\.?)(?:[.:]?)\\s+([^\\.\\n]+))\"\n",
    "\n",
    "# Regex für alle weiteren Abschnitte\n",
    "subsequent_pattern = r\"^(?:(\\d+\\.\\d*|AP \\d+\\.\\d*|AP \\d+:[.:]?|\\d+)[.:]?)\\s+([^\\.\\n]+)\"\n",
    "\n",
    "# Suche nach dem ersten Abschnitt\n",
    "first_match = re.search(first_pattern, text, re.MULTILINE)\n",
    "\n",
    "# Wenn der erste Match gefunden wurde, verarbeite die restlichen\n",
    "if first_match:\n",
    "    abschnitte = [f\"{first_match.group(1).strip()} {first_match.group(2).strip()}\"]\n",
    "    \n",
    "    # Schneide den Text ab dem ersten Match ab und suche nach den weiteren Abschnitten\n",
    "    remaining_text = text[first_match.end():]\n",
    "    subsequent_matches = re.findall(subsequent_pattern, remaining_text, re.MULTILINE)\n",
    "    \n",
    "    # Füge die restlichen Abschnitte hinzu\n",
    "    abschnitte.extend([f\"{num.strip()} {name.strip()}\" for num, name in subsequent_matches])\n",
    "else:\n",
    "    abschnitte = []  # Falls kein gültiger erster Abschnitt gefunden wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 Projekthintergrund und Zielsetzung 4', '1.1 Projekthintergrund 4', '1.2 Die doppelte Zielsetzung des Projekts 7', '2 Konzeption, Planung und Organisation des Dialogprozesses (AP 1) 10', '2.1 AP 1 Erarbeitung des Feinkonzepts 10', '2.2 Organisation und Prozesssteuerung 12', '2.3 Qualitätssicherung und Datenschutz 13', '3 Rekrutierung von Zufallsbürger*innen sowie Eingangs- und Ausgangsbefragungen 14', '3.1 Zufallsauswahl der Bürger*innen (AP 2) 14', '3.2 Eingangsbefragung (AP 3) 15', '3.3 Ausgangsbefragung und qualitative Erhebung (AP 5) 18', '4 Durchführung der Werkstätten und Workshops 22', '4.1 Durchführung der Bürgerwerkstätten (AP 4) 22', '4.2 Durchführung des Workshops der Bürgerbotschafter*innen (AP 6) 24', '4.3 Übergabe der Empfehlungen (AP 7) 25', '5 Berichterstattung 27', '5.1 Abschlussbericht (AP 8) 27', '6 Zeitplan 28', '7 Personal und Eignung 30', '7.1 Qualifikation der Projektverantwortlichen 30', '7.2 Referenzen 35', '7.3 Institutsbeschreibungen 46', '8 Kosten- und Zahlungsplan 48']\n"
     ]
    }
   ],
   "source": [
    "#print(abschnitte) #entkommentieren falls man testen will was gefunden wurde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###PDF Aufräumen und Abschnitte extrahieren###\n",
    "\n",
    "#Funktion um alles bis nach dem Innhaltsverzeichnis aus der pdf datei zu löschen, damit Inhaltsverzeichnis nicht erneut extrahiert wird\n",
    "def remove_pages_before_contents(pdf_path, output_path, contents_start_page=inhalt_end):\n",
    "    \"\"\"\n",
    "    Remove pages before the content starts (after the table of contents).\n",
    "    \n",
    "    :param pdf_path: Path to the original PDF file.\n",
    "    :param output_path: Path to save the new PDF file without the first pages.\n",
    "    :param contents_start_page: The page number (0-indexed) where the content starts.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    writer = PdfWriter()\n",
    "\n",
    "    # Add pages starting from the contents_start_page to the new PDF\n",
    "    for page_num in range(contents_start_page, len(reader.pages)):\n",
    "        writer.add_page(reader.pages[page_num])\n",
    "\n",
    "    # Write the new PDF to the output path\n",
    "    with open(output_path, \"wb\") as output_pdf:\n",
    "        writer.write(output_pdf)\n",
    "\n",
    "    print(f\"New PDF saved to: {output_path}\")\n",
    "\n",
    "#Funktion um die einzelnen Abschnitte zu finden und zu extrahieren\n",
    "def extract_sections_from_pdf(pdf_path, sections):\n",
    "    \"\"\"\n",
    "    Extract specified sections from a PDF file, starting at the match's start.\n",
    "\n",
    "    :param pdf_path: Path to the PDF file.\n",
    "    :param sections: List of section headings to extract.\n",
    "    :return: Dictionary with section headings as keys and extracted text as values.\n",
    "    \"\"\"\n",
    "    # Read the PDF\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "\n",
    "    # Combine text from all pages\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    # Prepare a regex pattern to match sections\n",
    "    sections_pattern = [re.escape(sec).replace(r'\\ ', r'\\s+') for sec in sections]\n",
    "    regex = re.compile(f\"({'|'.join(sections_pattern)})\", re.MULTILINE)\n",
    "\n",
    "\n",
    "    # Find matches and extract content\n",
    "    matches = list(regex.finditer(text))\n",
    "    extracted_sections = {}\n",
    "\n",
    "\n",
    "    # Loop through the matches to extract text for each section\n",
    "    for i, match in enumerate(matches):\n",
    "        start = match.start()  # Start from the beginning of the match\n",
    "\n",
    "        # Define the end position as the start of the next section or the end of the text\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "\n",
    "        # Extract the text for this section\n",
    "        section_text = text[start:end].strip()\n",
    "\n",
    "        # Store the extracted section text\n",
    "        extracted_sections[match.group()] = section_text\n",
    "\n",
    "    return extracted_sections\n",
    "\n",
    "pdf_path = file_path\n",
    "new_pdf_path = \"data/cleaned_pdf.pdf\"  # New PDF after removing pages up to the contents\n",
    "sections = abschnitte  # Liste der Abschnitte, die du extrahieren möchtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New PDF saved to: data/cleaned_pdf.pdf\n"
     ]
    }
   ],
   "source": [
    "# Call Funktion to remove pages before the table of contents\n",
    "remove_pages_before_contents(pdf_path, new_pdf_path, contents_start_page=2)  # Page 1 is the second page - Aktuell noch manuell die passende Seite eingegeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sections from the cleaned PDF\n",
    "extracted_sections = extract_sections_from_pdf(new_pdf_path, abschnitte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion um die extrahierten abschnitte in textdateien zu speichern\n",
    "def save_sections_as_text_files(extracted_sections, output_directory):\n",
    "    \"\"\"\n",
    "    Saves each section as a separate text file in the specified directory.\n",
    "    \n",
    "    :param extracted_sections: Dictionary with section names as keys and content as values.\n",
    "    :param output_directory: Directory where the text files will be saved.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    for section, content in extracted_sections.items():\n",
    "        # Sanitize the section name to make it a valid filename\n",
    "        filename = re.sub(r'[\\\\/*?:\"<>|]', \"_\", section)  # Replace invalid characters with underscores\n",
    "        file_path = os.path.join(output_directory, f\"{filename}.txt\")\n",
    "\n",
    "        # Write the content into the file\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(content)\n",
    "\n",
    "        print(f\"Section '{section}' saved to '{file_path}'\")\n",
    "\n",
    "\n",
    "output_directory = \"extracted_sections\"  # Directory to save the text files\n",
    "\n",
    "# Funktions aufrufen, um die Abschnitte in Textdateien zu speichern\n",
    "save_sections_as_text_files(extracted_sections, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexus_laptop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
